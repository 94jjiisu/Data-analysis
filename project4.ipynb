{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975cf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50484374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# tf.ones([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7364ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174af53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import urllib3\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from pickle import dump\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e47e8",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6508f7",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3f05f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"C:/Users/ST-USER/Desktop/project_4/les_miserables.txt\", 'r', encoding='utf-8')\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bed5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapitre I\n",
      "\n",
      "Monsieur Myriel\n",
      "\n",
      "\n",
      "En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\n",
      "C'était un vieillard d'environ soixante-quinze ans; il occupait le siège\n",
      "de Digne depuis 1806.\n",
      "\n",
      "Quoique ce détail ne touche en aucune manière au fond mê\n"
     ]
    }
   ],
   "source": [
    "print(data[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbccac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 길이: 3089743자\n"
     ]
    }
   ],
   "source": [
    "print ('텍스트의 길이: {}자'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfb2a1",
   "metadata": {},
   "source": [
    "## Vocabulary 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6348ada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 문자수 106개\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(data))\n",
    "print ('고유 문자수 {}개'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb0b22",
   "metadata": {},
   "source": [
    "## 문자 별 인덱스, 인덱스 별 문자 맵핑 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00bb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "\n",
    "# 인덱스에서 문자로 매핑\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2145e2e",
   "metadata": {},
   "source": [
    "## 생성된 맵핑 확인 : char2idx 20개 항목 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d17ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  \"'\" :   4,\n",
      "  '(' :   5,\n",
      "  ')' :   6,\n",
      "  '*' :   7,\n",
      "  '+' :   8,\n",
      "  ',' :   9,\n",
      "  '-' :  10,\n",
      "  '.' :  11,\n",
      "  '/' :  12,\n",
      "  '0' :  13,\n",
      "  '1' :  14,\n",
      "  '2' :  15,\n",
      "  '3' :  16,\n",
      "  '4' :  17,\n",
      "  '5' :  18,\n",
      "  '6' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21332a71",
   "metadata": {},
   "source": [
    "## 문자열 데이터를 숫자열 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50098471",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50eba0",
   "metadata": {},
   "source": [
    "## 문자열에서 숫자열로 맵핑 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9dbcb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Chapitre I\\n\\nM' ---- 문자들이 다음의 정수로 매핑되었습니다 ---- > [28 60 53 68 61 72 70 57  1 34  0  0 38]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트에서 처음 13개의 문자가 숫자로 어떻게 매핑되었는지를 보여줍니다\n",
    "print ('{} ---- 문자들이 다음의 정수로 매핑되었습니다 ---- > {}'.format(repr(data[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ec588",
   "metadata": {},
   "source": [
    "# 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd3fde6",
   "metadata": {},
   "source": [
    "## 1. 문자 단위 데이터 세트 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf1494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "h\n",
      "a\n",
      "p\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "# RNN 입력 sequence 길이\n",
    "seq_length = 100\n",
    "\n",
    "# 데이터셋 만들기\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "# 처음 5개 문자 확인\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a5978",
   "metadata": {},
   "source": [
    "## 2. 청크 단위 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d936cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Chapitre I\\n\\nMonsieur Myriel\\n\\n\\nEn 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\\nC'é\"\n",
      "\"tait un vieillard d'environ soixante-quinze ans; il occupait le siège\\nde Digne depuis 1806.\\n\\nQuoique \"\n",
      "\"ce détail ne touche en aucune manière au fond même de ce que\\nnous avons à raconter, il n'est peut-êtr\"\n",
      "\"e pas inutile, ne fût-ce que\\npour être exact en tout, d'indiquer ici les bruits et les propos qui\\nava\"\n",
      "\"ient couru sur son compte au moment où il était arrivé dans le\\ndiocèse. Vrai ou faux, ce qu'on dit de\"\n"
     ]
    }
   ],
   "source": [
    "# label 생성을 위해 배치 길이를 seq_length+1 설정\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "# 처음 5개 sequence 확인\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee385402",
   "metadata": {},
   "source": [
    "## 3. 입력과 타겟이 분리된 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d30961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf55d58",
   "metadata": {},
   "source": [
    "## 입력 & 타겟 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60831a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터:  \"Chapitre I\\n\\nMonsieur Myriel\\n\\n\\nEn 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\\nC'\"\n",
      "타깃 데이터:  \"hapitre I\\n\\nMonsieur Myriel\\n\\n\\nEn 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne.\\nC'é\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('입력 데이터: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('타깃 데이터: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d95ea",
   "metadata": {},
   "source": [
    "## 4. 배치 단위의 데이터 세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431cb212",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # 배치 크기\n",
    "BUFFER_SIZE = 10000 # 데이터셋을 섞을 버퍼 크기\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0186caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b6e17",
   "metadata": {},
   "source": [
    "# 모델 정의 - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee270f9f",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9b8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fdfe65",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "402e75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) # 어휘 사전의 크기\n",
    "embedding_dim = 256     # 임베딩 차원\n",
    "rnn_units = 1024        # RNN 유닛(unit) 개수\n",
    "\n",
    "model1 = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e1ad3",
   "metadata": {},
   "source": [
    "## 출력 Tensor Shape 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d70424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 106) # (배치 크기, 시퀀스 길이, 어휘 사전 크기)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model1(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (배치 크기, 시퀀스 길이, 어휘 사전 크기)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7839e7",
   "metadata": {},
   "source": [
    "## 모델 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30e11813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           27136     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 106)           108650    \n",
      "=================================================================\n",
      "Total params: 5,382,762\n",
      "Trainable params: 5,382,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae84ec",
   "metadata": {},
   "source": [
    "## 예측 분포에서 샘플링 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846f82e",
   "metadata": {},
   "source": [
    "### Categorical Distribution 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d1d0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (bach size, number of class)형태의 2D Tensor로 입력\n",
    "# 따라서, 100개의 timestep이 batch인 것으로 처리됨\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "\n",
    "# 출력이 (100,1)이므로 (100)으로 변경\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f219945",
   "metadata": {},
   "source": [
    "### 100개 timestep에 대한 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "813915eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 74,  67,  78,  15, 102,  46,  80,  60,  52,  17,  42,  33,  27,\n",
       "        45,  41,  55,  24,  16,  35,  93,  65,  15,   1,  36, 102,  22,\n",
       "        67,   3,  82,  54,  30,  69,  81,  75, 105,  20,   9,  24,  52,\n",
       "        24,  84,  47,   5,   2,  83,  14,  40,  99,  93,  32,   0,  37,\n",
       "         8,  35,  62, 102, 105,  72,  97,  90,  48,  12, 105,  38,  47,\n",
       "        83,  22, 101,  80,   0,  86,  30,  15,  42,   6,  14,  10,  60,\n",
       "         9,  72,  28,  13,  11,  37,  46,  52,   8,  98,  80,  27,  82,\n",
       "        28,  63,  92,  17,  94,  46,  85,   0,  55], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a76db",
   "metadata": {},
   "source": [
    "### 예측된 텍스트 복호화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0f2497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: \n",
      " \" c'est-à-dire à la nuit close, il\\npassait devant le théâtre de la Porte-Saint-Martin où l'on donnait\"\n",
      "\n",
      "예측된 다음 문자: \n",
      " 'voz2öU°h_4QHBTPc;3Jçm2 Kö9o\"»bEqºwü7,;_;ÂV(!À1OïçG\\nL+JjöütëàW/üMVÀ9ô°\\nÈE2Q)1-h,tC0.LU_+î°B»Ckæ4èUÇ\\nc'\n"
     ]
    }
   ],
   "source": [
    "print(\"입력: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"예측된 다음 문자: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6658c5",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573b500",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93243045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388891b",
   "metadata": {},
   "source": [
    "## 체크포인트 콜백 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0286d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트가 저장될 디렉토리\n",
    "checkpoint_dir1 = './training_checkpoints'\n",
    "# 체크포인트 파일 이름\n",
    "checkpoint_prefix1 = os.path.join(checkpoint_dir1, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback1=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix1,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07942a11",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ccc6fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "477/477 [==============================] - 18s 35ms/step - loss: 2.1644\n",
      "Epoch 2/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 1.5337\n",
      "Epoch 3/50\n",
      "477/477 [==============================] - 15s 31ms/step - loss: 1.3678\n",
      "Epoch 4/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.2954\n",
      "Epoch 5/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 1.2437\n",
      "Epoch 6/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.2080\n",
      "Epoch 7/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.1806\n",
      "Epoch 8/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 1.1565\n",
      "Epoch 9/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 1.1351\n",
      "Epoch 10/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.1148\n",
      "Epoch 11/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.0962\n",
      "Epoch 12/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.0773\n",
      "Epoch 13/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.0591\n",
      "Epoch 14/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.0414\n",
      "Epoch 15/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.0252\n",
      "Epoch 16/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 1.0079\n",
      "Epoch 17/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.9919\n",
      "Epoch 18/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.9760\n",
      "Epoch 19/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.9615\n",
      "Epoch 20/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.9473\n",
      "Epoch 21/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.9336\n",
      "Epoch 22/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.9204 0s - loss: \n",
      "Epoch 23/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.9085\n",
      "Epoch 24/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8969\n",
      "Epoch 25/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8864\n",
      "Epoch 26/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8769\n",
      "Epoch 27/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 0.8678\n",
      "Epoch 28/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 0.8591\n",
      "Epoch 29/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8518\n",
      "Epoch 30/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8439\n",
      "Epoch 31/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8377\n",
      "Epoch 32/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 0.8313\n",
      "Epoch 33/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8261\n",
      "Epoch 34/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8201\n",
      "Epoch 35/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8159\n",
      "Epoch 36/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8118\n",
      "Epoch 37/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8072\n",
      "Epoch 38/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8041\n",
      "Epoch 39/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.8007\n",
      "Epoch 40/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7964\n",
      "Epoch 41/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7948\n",
      "Epoch 42/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7909\n",
      "Epoch 43/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7887\n",
      "Epoch 44/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7880\n",
      "Epoch 45/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7853\n",
      "Epoch 46/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7848\n",
      "Epoch 47/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7829\n",
      "Epoch 48/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 0.7803\n",
      "Epoch 49/50\n",
      "477/477 [==============================] - 16s 32ms/step - loss: 0.7804\n",
      "Epoch 50/50\n",
      "477/477 [==============================] - 16s 33ms/step - loss: 0.7777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233d18763a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EPOCH = 50\n",
    "\n",
    "# # 체크포인트 콜백 설정\n",
    "# model1.fit(dataset, epochs=EPOCH, callbacks=[checkpoint_callback1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34b144f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8295201077785277440,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5736300544\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 17033106111397212744\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a678da49",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e13887b",
   "metadata": {},
   "source": [
    "### 모델을 테스트 하기 위해 훈련된 가중치를   갖고 배치 크기가 1인 입력을 받는 모델을 새로 만들어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbc526",
   "metadata": {},
   "source": [
    "## 테스트 용 모델을 새로 생성 (단, batch_size=1로 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "decbeb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5617357",
   "metadata": {},
   "source": [
    "## 모델에 마지막 저장 체크포인트 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a6397fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training_checkpoints\\ckpt_50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x233f1b1a850>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_checkpoint1 = tf.train.latest_checkpoint(checkpoint_dir1)\n",
    "print(last_checkpoint1)\n",
    "model1.load_weights(last_checkpoint1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd66e055",
   "metadata": {},
   "source": [
    "## 모델의 input shape을 [1, None]으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae897f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 크기 1로 모델을 새로 빌드\n",
    "model1.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d61ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            27136     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 106)            108650    \n",
      "=================================================================\n",
      "Total params: 5,382,762\n",
      "Trainable params: 5,382,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598d90d",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d267aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 사용하여 텍스트 생성\n",
    "def generate_text(model1, start_string, num_generate):\n",
    "  \n",
    "  num_generate = 50 # 생성할 문자의 수\n",
    "\n",
    "  # 시작 문자열을 숫자열로 변환\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0) # 2차원 배열로 변환\n",
    "\n",
    "  text_generated = [] # 생성된 결과를 저장할 빈 문자열\n",
    "\n",
    "  # temperature로 확률 값 조정 – 크면 균등분포, 낮으면 argmax와 같이 됨\n",
    "  temperature = 1.0\n",
    "\n",
    "  model1.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model1(input_eval) # 배치 크기 = 1\n",
    "      predictions = tf.squeeze(predictions, 0) # 배치 차원 제거\n",
    "      predictions = predictions / temperature # temperature 적용\n",
    "    \n",
    "    \n",
    "      # 범주형 분포를 사용하여 모델에서 리턴한 단어 예측\n",
    "      # input   : [batch_size, num_classes]  RNN sequence를 batch 형태로 입력\n",
    "      # output : [batch_size, num_samples] [-1,0]는 마지막 batch 항목에서 첫번째로 sampling한 값을 의미\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # 예측된 단어를 다음 입력으로 모델에 전달\n",
    "      input_eval = tf.expand_dims([predicted_id], 0) # 2차원 배열로 변환\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id]) # 생성된 문자열에 추가\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "999930d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je suis tonnante:\n",
      "\n",
      "--Venez les êtres d'une patodilition de\n"
     ]
    }
   ],
   "source": [
    "lstm_text1 = generate_text(model1, start_string=u\"Je suis \", num_generate=5)\n",
    "print(lstm_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "75fba438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a tir dans les bois. Au peuple, était de la\n",
      "fumée et\n"
     ]
    }
   ],
   "source": [
    "lstm_text2 = generate_text(model1, start_string=u\"Il y a \", num_generate=5)\n",
    "print(lstm_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf9584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818994d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f85ac112",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"C:/Users/ST-USER/Desktop/project_4/les_miserables.txt\", 'r', encoding='utf-8')\n",
    "data2 = f2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "349af567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 길이: 3089743자\n"
     ]
    }
   ],
   "source": [
    "print ('텍스트의 길이: {}자'.format(len(data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bc76b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4af42026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    doc = doc.lower()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e68c8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = clean_doc(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9c6ce",
   "metadata": {},
   "source": [
    "# 좀 더 다듬은 GRU 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c88c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'()*+,-./0123456789:;?_abcdefghijklmnopqrstuvwxyz«°º»àâæçèéêëîïñôöùûü'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(data2.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f80703ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b41c36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 6, 5, 2, 8, 3, 24, 10, 2, 5]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"miserables\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e92b910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m t i e u a h l e i']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[14, 4, 6, 2, 9, 3, 25, 10, 2, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "535ee144",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size = tokenizer.document_count # total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b34f9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([data2])) - 1\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb5fe366",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "200e767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4683f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8527411",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e71aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b2a2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d16c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 73) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3d697c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc312dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a5267af",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir2 = './training_checkpoints_full_text'\n",
    "# 체크포인트 파일 이름\n",
    "checkpoint_prefix2 = os.path.join(checkpoint_dir2, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix2,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "98b1c7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 128)         77952     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 128)         99072     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 73)          9417      \n",
      "=================================================================\n",
      "Total params: 186,441\n",
      "Trainable params: 186,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5b57eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training_checkpoints_full_text\\ckpt_10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x233f1ba2c40>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_checkpoint2 = tf.train.latest_checkpoint(checkpoint_dir2)\n",
    "print(last_checkpoint2)\n",
    "model2.load_weights(last_checkpoint2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "955474d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCH = 10\n",
    "\n",
    "# # 체크포인트 콜백 설정\n",
    "# model.fit(dataset, epochs=EPOCH, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c86f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa015a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6fb8a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = preprocess([\"Je sui\"])\n",
    "#Y_pred = model.predict_classes(X_new)\n",
    "Y_pred = np.argmax(model2(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c83ed0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        2, 0, 0, 1, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "37b37ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char2(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model2(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "28b38b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "next_char2(\"Je sui\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ad517133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text2(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char2(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "25ba478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jean valjean se trouva le corps en percé de la rue.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text2(\"J\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d97f6e52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e ne poccergent teus pied à la porte,\n",
      "c'est terribl\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text2(\"e\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6424d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je suis bongé, il est teusonne glande\n",
      "par bout à la raiso\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "gru_text1 = complete_text2(\"Je suis\", temperature=1)\n",
    "print(gru_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ed00d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a pas toccourement un signe d'un cachet. jean valjea\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "gru_text2 = complete_text2(\"Il y a \", temperature=1)\n",
    "print(gru_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5b29d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "### new_model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "#                      #dropout=0.2, recurrent_dropout=0.2),\n",
    "#                      dropout=0.2),\n",
    "#     tf.keras.layers.GRU(128, return_sequences=True,\n",
    "#                      #dropout=0.2, recurrent_dropout=0.2),\n",
    "#                      dropout=0.2),\n",
    "#     tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "#                                                     activation=\"softmax\"))\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea11c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_checkpoint2 = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# print(last_checkpoint2)\n",
    "# new_model.load_weights(last_checkpoint2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8697d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def next_char2(text, temperature=1):\n",
    "#     X_new = preprocess([text])\n",
    "#     y_proba = new_model(X_new)[0, -1:, :]\n",
    "#     rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "#     char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "#     return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d679b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_text('Je suis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f2408",
   "metadata": {},
   "source": [
    "# Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "950ea50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ddc358b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9975e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfc78871",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2,\n",
    "                     dropout=0.2,\n",
    "                     batch_input_shape=[batch_size, None, max_id]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8dafdfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed95de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "# history = model3.fit(dataset, epochs=50,\n",
    "#                     callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "6ff0f397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, None, 128)         77952     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, None, 128)         99072     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 73)          9417      \n",
      "=================================================================\n",
      "Total params: 186,441\n",
      "Trainable params: 186,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2f32bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff batch size\n",
    "stateless_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c90eb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None, max_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9bf0cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.load_weights('stateless_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "af99eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stateless_model.set_weights(model3.get_weights())\n",
    "model3 = stateless_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "88eadbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char3(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model3(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8f7ee807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text3(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char3(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "9f6276d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-il pocricle _pour ayant l'autre\n",
      "chose. moite avai\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text3(\"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "c388e11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je suis pas locricle de\n",
      "cours _dans les jours.\n",
      "\n",
      "   t il y \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "state_text1 = complete_text3(\"Je suis \")\n",
    "print(state_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c62aa0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a pas pocricle de\n",
      "cosette grande la porte qui lua so\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "state_text2 = complete_text3(\"Il y a \")\n",
    "print(state_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "7403af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_state.save_weights('stateless_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd8769",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26873d0",
   "metadata": {},
   "source": [
    "# 기계번역"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96442f38",
   "metadata": {},
   "source": [
    "# 학습 가능한 형태로 코퍼스를 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "18f74b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 190000 # 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3de657b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fra.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, fra = line.split(\"\\t\")\n",
    "    eng = \"[start] \" + eng + \" [end]\"\n",
    "    text_pairs.append((eng, fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7492f549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"[start] Tom's new girlfriend is quite attractive. [end]\", 'La nouvelle copine de Tom est plutôt séduisante.')\n",
      "(\"[start] I haven't seen you around before. [end]\", \"Je ne t'ai pas vu auparavant dans les environs.\")\n",
      "('[start] They were afraid of being overheard. [end]', \"Elles ont craint d'être écoutées.\")\n",
      "(\"[start] I'd like you to mail this letter. [end]\", \"J'aimerais que tu postes cette lettre.\")\n",
      "(\"[start] I'm not sure that that's true. [end]\", 'Je ne suis pas sûr que ça soit vrai.')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b45842b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167130 total pairs\n",
      "116992 training pairs\n",
      "25069 validation pairs\n",
      "25069 test pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "034916be",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = string.punctuation + \"?\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "\n",
    "fra_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
    ")\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_fra_texts = [pair[1] for pair in train_pairs]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "fra_vectorization.adapt(train_fra_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d3fb86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(eng, fra):\n",
    "    eng = eng_vectorization(eng)\n",
    "    fra = fra_vectorization(fra)\n",
    "    return ({\"encoder_inputs\": fra, \"decoder_inputs\": eng[:, :-1],}, eng[:, 1:])\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, fra_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    fra_texts = list(fra_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fra_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2d59d01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad8a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b20b110",
   "metadata": {},
   "source": [
    "# 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3a1a652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'dense_dim': self.dense_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "    \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'embed_dim': self.embed_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    \n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9395f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b43ec46",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7f9d940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positional_embedding_4 (Positio (None, None, 256)    3845120     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_2 (Transfor (None, None, 256)    3155456     positional_embedding_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Functional)            (None, None, 15000)  12959640    decoder_inputs[0][0]             \n",
      "                                                                 transformer_encoder_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 19,960,216\n",
      "Trainable params: 19,960,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 30  # This should be at least 30 for convergence\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bdbab801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "1828/1828 [==============================] - 88s 46ms/step - loss: 1.3392 - accuracy: 0.5094 - val_loss: 1.0364 - val_accuracy: 0.6006\n",
      "Epoch 2/30\n",
      "1828/1828 [==============================] - 83s 46ms/step - loss: 0.9810 - accuracy: 0.6301 - val_loss: 0.8738 - val_accuracy: 0.6655\n",
      "Epoch 3/30\n",
      "1828/1828 [==============================] - 83s 45ms/step - loss: 0.8635 - accuracy: 0.6742 - val_loss: 0.8339 - val_accuracy: 0.6862\n",
      "Epoch 4/30\n",
      "1828/1828 [==============================] - 83s 45ms/step - loss: 0.8064 - accuracy: 0.7008 - val_loss: 0.8049 - val_accuracy: 0.7013\n",
      "Epoch 5/30\n",
      "1828/1828 [==============================] - 83s 45ms/step - loss: 0.7686 - accuracy: 0.7197 - val_loss: 0.7893 - val_accuracy: 0.7128\n",
      "Epoch 6/30\n",
      "1828/1828 [==============================] - 85s 46ms/step - loss: 0.7432 - accuracy: 0.7335 - val_loss: 0.7820 - val_accuracy: 0.7185\n",
      "Epoch 7/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.7219 - accuracy: 0.7445 - val_loss: 0.7776 - val_accuracy: 0.7225\n",
      "Epoch 8/30\n",
      "1828/1828 [==============================] - 87s 47ms/step - loss: 0.7034 - accuracy: 0.7542 - val_loss: 0.7729 - val_accuracy: 0.7263\n",
      "Epoch 9/30\n",
      "1828/1828 [==============================] - 84s 46ms/step - loss: 0.6872 - accuracy: 0.7622 - val_loss: 0.7687 - val_accuracy: 0.7327\n",
      "Epoch 10/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.6725 - accuracy: 0.7691 - val_loss: 0.7677 - val_accuracy: 0.7329\n",
      "Epoch 11/30\n",
      "1828/1828 [==============================] - 87s 47ms/step - loss: 0.6587 - accuracy: 0.7756 - val_loss: 0.7644 - val_accuracy: 0.7353\n",
      "Epoch 12/30\n",
      "1828/1828 [==============================] - 87s 47ms/step - loss: 0.6470 - accuracy: 0.7808 - val_loss: 0.7641 - val_accuracy: 0.7370\n",
      "Epoch 13/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.6357 - accuracy: 0.7856 - val_loss: 0.7626 - val_accuracy: 0.7398\n",
      "Epoch 14/30\n",
      "1828/1828 [==============================] - 88s 48ms/step - loss: 0.6240 - accuracy: 0.7902 - val_loss: 0.7671 - val_accuracy: 0.7397\n",
      "Epoch 15/30\n",
      "1828/1828 [==============================] - 88s 48ms/step - loss: 0.6136 - accuracy: 0.7942 - val_loss: 0.7617 - val_accuracy: 0.7425\n",
      "Epoch 16/30\n",
      "1828/1828 [==============================] - 84s 46ms/step - loss: 0.6042 - accuracy: 0.7978 - val_loss: 0.7688 - val_accuracy: 0.7405\n",
      "Epoch 17/30\n",
      "1828/1828 [==============================] - 88s 48ms/step - loss: 0.5981 - accuracy: 0.8005 - val_loss: 0.7747 - val_accuracy: 0.7386\n",
      "Epoch 18/30\n",
      "1828/1828 [==============================] - 85s 47ms/step - loss: 0.5912 - accuracy: 0.8044 - val_loss: 0.7697 - val_accuracy: 0.7408\n",
      "Epoch 19/30\n",
      "1828/1828 [==============================] - 87s 47ms/step - loss: 0.5826 - accuracy: 0.8073 - val_loss: 0.7704 - val_accuracy: 0.7406\n",
      "Epoch 20/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.5752 - accuracy: 0.8098 - val_loss: 0.7691 - val_accuracy: 0.7453\n",
      "Epoch 21/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.5673 - accuracy: 0.8129 - val_loss: 0.7676 - val_accuracy: 0.7454\n",
      "Epoch 22/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.5613 - accuracy: 0.8153 - val_loss: 0.7784 - val_accuracy: 0.7432\n",
      "Epoch 23/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.5548 - accuracy: 0.8176 - val_loss: 0.7769 - val_accuracy: 0.7434\n",
      "Epoch 24/30\n",
      "1828/1828 [==============================] - 88s 48ms/step - loss: 0.5488 - accuracy: 0.8196 - val_loss: 0.7761 - val_accuracy: 0.7456\n",
      "Epoch 25/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.5433 - accuracy: 0.8217 - val_loss: 0.7836 - val_accuracy: 0.7431\n",
      "Epoch 26/30\n",
      "1828/1828 [==============================] - 86s 47ms/step - loss: 0.5391 - accuracy: 0.8238 - val_loss: 0.7798 - val_accuracy: 0.7472\n",
      "Epoch 27/30\n",
      "1828/1828 [==============================] - 85s 46ms/step - loss: 0.5345 - accuracy: 0.8254 - val_loss: 0.7885 - val_accuracy: 0.7434\n",
      "Epoch 28/30\n",
      "1828/1828 [==============================] - 85s 46ms/step - loss: 0.5298 - accuracy: 0.8271 - val_loss: 0.7939 - val_accuracy: 0.7435\n",
      "Epoch 29/30\n",
      "1828/1828 [==============================] - 85s 47ms/step - loss: 0.5266 - accuracy: 0.8278 - val_loss: 0.8046 - val_accuracy: 0.7427\n",
      "Epoch 30/30\n",
      "1828/1828 [==============================] - 88s 48ms/step - loss: 0.5222 - accuracy: 0.8298 - val_loss: 0.7858 - val_accuracy: 0.7473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233f1dd7760>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir4 = './translator_checkpoints2'\n",
    "# 체크포인트 파일 이름\n",
    "checkpoint_prefix4 = os.path.join(checkpoint_dir4, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix4,\n",
    "    save_weights_only=True,\n",
    "    save_freq = 10)\n",
    "\n",
    "\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "012ae6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./translator_checkpoints2\\ckpt_30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x233f1dd7460>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_checkpoint4 = tf.train.latest_checkpoint(checkpoint_dir4)\n",
    "print(last_checkpoint4)\n",
    "transformer.load_weights(last_checkpoint4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4f50c",
   "metadata": {},
   "source": [
    "# 문장 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f365a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = eng_vectorization.get_vocabulary()\n",
    "eng_index_lookup = dict(zip(range(len(eng_vocab)), eng_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = fra_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = eng_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = eng_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "test_fra_texts = [pair[1] for pair in test_pairs]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_fra_texts)\n",
    "    translated = decode_sequence(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "71dfee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] three [end]'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(\"trois poem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3326368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "transformer.save_weights('translator_1')\n",
    "# new_model = tf.keras.models.load_model('iris.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c0351cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_last = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2078f287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2359d4236a0>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_last.load_weights(\"translator_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f3e860ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_last\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positional_embedding_4 (Positio (None, None, 256)    3845120     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_2 (Transfor (None, None, 256)    3155456     positional_embedding_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Functional)            (None, None, 15000)  12959640    decoder_inputs[0][0]             \n",
      "                                                                 transformer_encoder_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 19,960,216\n",
      "Trainable params: 19,960,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer_last.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1b59842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence2(input_sentence):\n",
    "    tokenized_input_sentence = fra_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = eng_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer_last([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = eng_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "test_fra_texts = [pair[1] for pair in test_pairs]\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_fra_texts)\n",
    "    translated = decode_sequence2(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fc208ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] thank you the woman [end]'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence2(\"cherche la femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5ebc79a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] how do you say [end]'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence2(\"comment te dire adieu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3a7fa0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] its life [end]'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence2(\"c'est a vie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13894e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "721ebf2f",
   "metadata": {},
   "source": [
    "# 문장 생성과 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "66d51a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je suis tonnante:\\n\\n--Venez les êtres d'une patodilition de\""
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "b33ba3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je suis tonnante    Venez les êtres d'une patodilition de\""
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_text1 = lstm_text1.replace(\"\\n\", ' ')\n",
    "lstm_text1 = lstm_text1.replace(\":\", '')\n",
    "lstm_text1 = lstm_text1.replace(\",\", '')\n",
    "lstm_text1 = lstm_text1.replace(\";\", '')\n",
    "lstm_text1 = lstm_text1.replace(\"?\", ' ')\n",
    "lstm_text1 = lstm_text1.replace(\"-\", ' ')\n",
    "lstm_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "36a5f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trans1 = \"I'm amazing Come the beings of a patodilition of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "41f7fcbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] i am a [end]'"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_result1 = decode_sequence2(lstm_text1)\n",
    "lstm_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "5da8256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il y a tir dans les bois. Au peuple, était de la\\nfumée et'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "864f8bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il y a tir dans les bois. Au peuple était de la fumée et'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_text2 = lstm_text2.replace(\"\\n\", ' ')\n",
    "lstm_text2 = lstm_text2.replace(\":\", '')\n",
    "lstm_text2 = lstm_text2.replace(\",\", '')\n",
    "lstm_text2 = lstm_text2.replace(\";\", '')\n",
    "lstm_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "b2d1743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trans2 = \"There is shooting in the woods. To the people was smoke and\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "788dffed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] there are have have have a good time at the to get used to the people [end]'"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_result2 = decode_sequence2(lstm_text2)\n",
    "lstm_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70fbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97cea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1623d7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je suis bongé, il est teusonne glande\\npar bout à la raiso'"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "1b159f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je suis bongé il est teusonne glande par bout à la raiso'"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_text1 = gru_text1.replace(\"\\n\", ' ')\n",
    "gru_text1 = gru_text1.replace(\":\", '')\n",
    "gru_text1 = gru_text1.replace(\",\", '')\n",
    "gru_text1 = gru_text1.replace(\";\", '')\n",
    "gru_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "68a68b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_trans1 = \"I'm good, he's a bit of a pain at the end of the day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "856b1dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] i was a [end]'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_result1 = decode_sequence2(gru_text1)\n",
    "gru_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "0f182f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Il y a pas toccourement un signe d'un cachet. jean valjea\""
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_text2 = gru_text2.replace(\"\\n\", ' ')\n",
    "gru_text2 = gru_text2.replace(\":\", '')\n",
    "gru_text2 = gru_text2.replace(\",\", '')\n",
    "gru_text2 = gru_text2.replace(\";\", '')\n",
    "gru_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d27dd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_trans2 = \"There is not toccourement a sign of a cachet. jean valjea\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "9624bd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] there is no the [end]'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_result2 = decode_sequence2(gru_text2)\n",
    "gru_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402644c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "406a04c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je suis pas locricle de\\ncours _dans les jours.\\n\\n   t il y '"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "8cc2b4fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je suis pas locricle de cours dans les jours.     t il y '"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_text1 = state_text1.replace(\"\\n\", ' ')\n",
    "state_text1 = state_text1.replace(\":\", '')\n",
    "state_text1 = state_text1.replace(\",\", '')\n",
    "state_text1 = state_text1.replace(\";\", '')\n",
    "state_text1 = state_text1.replace(\"_\", '')\n",
    "state_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "e2908246",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_trans1 = \"I don't follow the course during the day. t there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "c0cbc01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] i dont go to class at the days there are [end]'"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_result1 = decode_sequence2(state_text1)\n",
    "state_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142be91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "80244c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il y a pas pocricle de\\ncosette grande la porte qui lua so'"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e6777986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il y a pas pocricle de cosette grande la porte qui lua so'"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_text2 = state_text2.replace(\"\\n\", ' ')\n",
    "state_text2 = state_text2.replace(\":\", ' ')\n",
    "state_text2 = state_text2.replace(\",\", ' ')\n",
    "state_text2 = state_text2.replace(\";\", ' ')\n",
    "state_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "cad73a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_trans2 = \"There is no grand cosette pocricle the door that lua so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "68629587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] there is no [end]'"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_result2 = decode_sequence2(state_text2)\n",
    "state_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75028fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "5e7a0deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je per qu'il avait que l'idée de génie à convoit du \n",
      "[start] i had that he a blue idea down from the [end]\n"
     ]
    }
   ],
   "source": [
    "lstm_text3 = generate_text(model1, start_string=u\"Je\", num_generate=5)\n",
    "#print(lstm_text3)\n",
    "\n",
    "lstm_text3 = lstm_text3.replace(\"\\n\", ' ')\n",
    "lstm_text3 = lstm_text3.replace(\":\", ' ')\n",
    "lstm_text3 = lstm_text3.replace(\",\", ' ')\n",
    "lstm_text3 = lstm_text3.replace(\";\", ' ')\n",
    "print(lstm_text3)\n",
    "lstm_result3 = decode_sequence2(lstm_text3)\n",
    "print(lstm_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "7257f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_trans3 = \"I perceive that he had only the idea of genius to covet the\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "40e1b678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je ne poccienne pas son ligne de la porte et terribl\n",
      "[start] i wont get his line door and closed [end]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "gru_text3 = complete_text2(\"Je\", temperature=1)\n",
    "#print(gru_text3)\n",
    "gru_text3 = gru_text3.replace(\"\\n\", ' ')\n",
    "gru_text3 = gru_text3.replace(\":\", ' ')\n",
    "gru_text3 = gru_text3.replace(\",\", ' ')\n",
    "gru_text3 = gru_text3.replace(\";\", ' ')\n",
    "print(gru_text3)\n",
    "gru_result3 = decode_sequence2(gru_text3)\n",
    "print(gru_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "c55bf195",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_trans3 = 'I do not poccienne its line of the door and terribl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "b04962f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je n'avocaile dite que la larre na poussa dit  armo\n",
      "[start] i gave the the the the the [end]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "state_text3 = complete_text3(\"Je\")\n",
    "#print(state_text3)\n",
    "state_text3 = state_text3.replace(\"\\n\", '')\n",
    "state_text3 = state_text3.replace(\":\", ' ')\n",
    "state_text3 = state_text3.replace(\",\", ' ')\n",
    "state_text3 = state_text3.replace(\";\", ' ')\n",
    "print(state_text3)\n",
    "state_result3 = decode_sequence2(state_text3)\n",
    "print(state_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "0c05975c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je n'avocaile dite que la larre na poussa dit  armo\""
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "316fee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_trans3 = \"I only avocado said that the larre na pushed said armo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "defa2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "a342429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\main\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\main\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\main\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4488496539373276e-231"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(lstm_trans1.split(), lstm_result1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "5d23a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.844844403089352e-232"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(lstm_trans2.split(), lstm_result2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "bdb38f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1640469867513693e-231"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(lstm_trans3.split(), lstm_result3.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a4f156ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4488496539373276e-231"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(gru_trans1.split(), gru_result1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "af44fdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0003688322288243e-231"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(gru_result2.split(),gru_trans2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "bc8217d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0244914152188952e-231"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(gru_trans3.split(), gru_result3.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "3361d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0244914152188952e-231"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(state_trans1.split(), state_result1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "21f409d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(state_trans2.split(), state_result2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "5be3e64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0518351895246305e-231"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.sentence_bleu(state_trans3.split(), state_result3.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "9ef9d821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "cdc9a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-sys.version—\n",
      "3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"-sys.version—\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "4fc930f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Mon_Sep_13_20:11:50_Pacific_Daylight_Time_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.50\n",
      "Build cuda_11.5.r11.5/compiler.30411180_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283605dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
